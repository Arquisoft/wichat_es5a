ifndef::imagesdir[:imagesdir: ../images]

[[section-testing]]
== Test

=== Test unitarios
Hemos realizado diversos test para cada servicio de la aplicación usando Jest y Testing Library de React. Para cada componente del Webapp por ejemplo hemos creado una clase test propia para probar sus funcionalidades, así como para cada servicio del backend.

Este ha sido un proceso que hemos desarrollado a lo largo del proyecto y del cual nos hemos ayudado de la herramiennta SonarCloud que analiza el código de nuestro repositorio de GitHub para decirnos cual es nuestro porcentaje de código cubierto por test, así como las posibles brechas de seguridad que puede tener la aplicación(muchas de estas falsos positivos).

Aunque el porcentaje pueda variar un poco al final del proyecto hemos conseguido superar un 80% de coverage para el código global de la aplicación. Requisito necesario para que la aplicación tenga suficientes test.

image::Test_unitarios.png["Test unitarios"]

=== Test de Usabilidad

Hemos realizado dos tandas con usuarios tanto en el sprint 3 como en el sprint 4 para que probaran la aplicación desplegada.

Estos usuarios eran personas jóvenes de entre 20 y 30 años de edad, bastante familiarizados con las aplicaciones web en general, por lo que la curva de aprendizaje fue bastante rápida y no supuso un gran problema.

Algunos de los problemas que encontraron los usuarios y que nos parecieron relevantes fueron:

==== Sprint 3
* Las preguntas en difícil tardan bastante en generar(1 minuto).
* La ventana del chat tapa su propio botón de cerrar.
* El botón siguiente pregunta se va desplazando hacia abajo con cada click.
* La primera vez que le das al botón de iniciar sesión no va, tienes que darle dos veces.

==== Sprint 4
* El botón del LLM no era intuitivo para su uso, haciendo que el usuario no supiera si estaba desactivado.
* Algunas preguntas de comida enseñaban códigos en vez de respuestas.
* Un bug en el modo supervivencia que hacía que se repitiese la misma pregunta a partir de la 20.

=== Test E2E
Para la realización de test End to End hemos usado el framework de Cucumber. Los test E2E son pruebas automatizadas que validan el funcionamiento de una aplicación desde el punto de vista del usuario final. Su objetivo es comprobar que todos los componentes del sistema como el front, back, base de datos y demás, funcionen juntos como se espera.

Nosotros hemos implementado 3 features a los test, siendo estas:
* **Game:**Simulará al jugador jugando juegos en distintas dificultades e interactuando con el LLM mientras juega.
* **Login-form:**Simulará el formulario de registro y los posibles errores que puede cometer el usuario al meter datos incorrectos o no estar registrado.
* **Register-form:**Simulará el formulario de identificación de usuario y los posibles errores que puede cometer el usuario al meter datos incorrectos.

=== Test de carga
Para realizar los test de carga hemos usado la herramienta Gatling, usando el lenguaje scala para crear los distintos programas y haciendo uso de la funcionalidad de recorder de Gatling para "grabar" los movimientos de un usuario por la aplicación y luego adaptarlos a los test de carga.

Hemos probado los test de carga con la aplicación deplegada, ya que si lo hicieramos en local, se tendrían en cuenta los componentes de nuestro sistema. Además se ha creado una función en los programas que aleatoriza la creación de usuarios, siendo casi imposible que dos usuarios tengan el mismo nombre, correo u contraseña(aunque esta última podría ser igual).

Los pasos que hemos grabado han sido los siguientes: Identificar un nuevo usuario en la aplicación, después hacer login, jugar a un juego en dificultad fácil de 5 preguntas, pedirle una pista al LLM entre medias y por último, guardar la puntuación del juego y mirar el historial. Hemos realizado dos pruebas, una para probar que la aplicación puede aguantar un nivel moderado de usuarios concurrentes y otra exhaustiva para poder ver los cuellos de botella de la aplicación y el margen de mejora.

==== 120 usuarios en 60 segundos
Hay que aclarar antes de este punto, que teníamos un diagrama de 120 usuarios con todas las peticiones OK y en verde, pero por malas praxis, acabamos perdiendolo, lo que pasa es que al volver a ejecutar el programa había un apagón en la zona, que hizo que incluso el día despúes el wifi no fuera. Por lo que al ejecutarse con mala conexión hace timeout en 11 peticiones y eleva el tiempo de las demás.

Podemos ver que en este test que casi todas las peticiones se realizan en un tiempo razonable, habiendo bastante pocas peticiones que tarden bastante, con esto podemos comprobar que la aplicación es estable con un número adecuado de usuarios que no debería darnos problema a la hora de entregar el proyecto al solicitante.

image::Carga1.png["Carga 1"]

image::Carga2.png["Carga 2"]

link:../../gatling/Resultados/Prueba_120_usuarios/index.html[Ver resultados de rendimiento primer esquema]

==== 1800 usuarios en 60 segundos
Aquí podemos ya ver bastantes errores graves, un cuarto de las peticiones fallan ante tal cantidad de usuarios.

El problema principal está en que el backend, se satura de usuarios y deja de funcionar. Haciendo que peticiones como AddUser o Login dejen de funcionar, pero otros servicios como la petición al LLM o la generación de preguntas con WikiData aguantan bastante bien. También cabe destacar el 100% de error a la hora de la entrega de la css de la aplicación, lo que genera que ningún usuario pueda ver la aplicación con normalidad. 

El problema creemos que está en la potencia de nuestra máquina virtual, la cual tendríamos que cambiar por una más potente, con mejor memoria y rendimiento para que el backend pudiera aguantar más carga de usuarios.

image::Carga3.png["Carga 3"]

image::Carga4.png["Carga 4"]

link:../../gatling/Resultados/Prueba_1800_usuarios/index.html[Ver resultados de rendimiento segundo esquema]

=== Monitorización
También hemos realizado monitorización de la aplicación usando las herramientas de Prometheus y Grafana para observar el comportamiento en tiempo real de la aplicación para poder asegurarse de que esta funcione correctamente y detectar sus problemas rápidamente y mejorar su rendimiento.

Monitorizar una aplicación nos sirve para tener:
* Buena disponibilidad
* Mejor rendimiento 
* Detección temprana de errores
* Controlar el recorrido de los usuarios
* En caso de fallo, generación de alertas

Al final, el objetivo es anticiparse a los problemas y mejorar continuamente la calidad y eficiencia de la aplicación.